{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para utilizar a API do Google Sheets, é necessário seguir os passos 1 e 2 do seguinte link:\n",
    "#https://developers.google.com/sheets/api/quickstart/python\n",
    "\n",
    "#bibliotecas para pegar a planilha\n",
    "from __future__ import print_function\n",
    "import pickle\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pandas as pd   #para utilizar o Pandas\n",
    "import re   #para utilizar a função \"re.sub\"\n",
    "from datetime import datetime   #para utilizar a função \"datetime.strptime\" \n",
    "import xml.etree.ElementTree as et   #para importar o arquivo xml\n",
    "import sqlite3  #para utilizar o sqlite\n",
    "from sqlalchemy import create_engine   #para inserir os dados na tabela do bd\n",
    "\n",
    "\n",
    "#Se estiver modificando esses escopos, exclua o arquivo token.pickle\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "\n",
    "SAMPLE_SPREADSHEET_ID = '1N6JFMIQR71HF5u5zkWthqbgpA8WYz_0ufDGadeJnhlo'   #ID da tabela\n",
    "SAMPLE_RANGE_NAME = ['usuarios','dependentes']   #Nome das duas páginas da tabela\n",
    "\n",
    "\n",
    "def get_google_sheet(spreadsheet_id, range_name):   #Pega a tabela e joga em um dataframe\n",
    "    creds = None\n",
    "    #Checagem do arquivo token.pickle, que armazena os tokens de acesso e de atualização do usuário, e é \n",
    "    #criado automaticamente quando o fluxo de autorização é concluído pela primeira vez.\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    #Se não houver credenciais (válidas) disponíveis, é solicitado o login do usuário\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server()\n",
    "        #Salva as credenciais para uma tentativa futura\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    sheet = service.spreadsheets()   #Chamada da API\n",
    "    \n",
    "    df = {}   #Criação do dict\n",
    "    \n",
    "    for name in range_name:   #passa pela lista de páginas da tabela\n",
    "        #utiliza o id da tabela e a página atual, para pegar dados de cada página\n",
    "        result = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=name).execute()\n",
    "        \n",
    "\n",
    "        header = result.get('values', [])[0]    #Assume-se que a primeira linha é o cabeçalho\n",
    "        values = result.get('values', [])[1:]   #E que o resto são os dados\n",
    "\n",
    "        if not values:\n",
    "            print('No data found.')\n",
    "        else:\n",
    "            all_data = []\n",
    "            for col_id, col_name in enumerate(header):\n",
    "                column_data = []\n",
    "                for row in values:\n",
    "                    try:   #tenta adicionar o valor\n",
    "                        column_data.append(row[col_id])\n",
    "                    except:   #se der erro, adiciona None\n",
    "                        column_data.append(None)\n",
    "                ds = pd.Series(data=column_data, name=col_name)\n",
    "                all_data.append(ds)\n",
    "            df[name] = pd.concat(all_data, axis=1)   #dict da folha atual recebe o dataframe\n",
    "            \n",
    "    return df\n",
    "\n",
    "#chamada da função, atribuindo os dataframes criados à variável df\n",
    "df = get_google_sheet(SAMPLE_SPREADSHEET_ID, SAMPLE_RANGE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importação de csv\n",
    "columns = [\"id\", \"nome\", \"email\", \"telefone\", \"valor\", \"desconto\"]   #definição do nome das colunas\n",
    "tabela_csv = pd.read_csv('dataApr-1-2019.csv', delimiter=';', names=columns, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importa_xml(arquivo_xml, df_colunas):   #importação de xml, recebe o arquivo xml e o nome das colunas\n",
    "        \n",
    "    xtree = et.parse(arquivo_xml)\n",
    "    xroot = xtree.getroot()   #pega os dados do arquivo\n",
    "    tabela_xml = pd.DataFrame(columns = df_colunas)   #gera o dataframe com as colunas nomeadas\n",
    "    \n",
    "    for node in xroot:   #adiciona os dados no dataframe\n",
    "        res = []\n",
    "        #res.append(node.attrib.get(df_colunas[0]))   Não utilizado para esse arquivo\n",
    "        for el in df_colunas[0:]: \n",
    "            if node is not None and node.find(el) is not None:\n",
    "                res.append(node.find(el).text)\n",
    "            else: \n",
    "                res.append(None)\n",
    "        tabela_xml = tabela_xml.append(pd.Series(res, index = df_colunas), ignore_index = True)\n",
    "        \n",
    "    return tabela_xml\n",
    "\n",
    "tabela_xml = importa_xml('dataApr-1-2019 2.xml', [\"user_id\", \"name\", \"email_user\", \"phone\", \"buy_value\"])\n",
    "tabela_xml['desconto'] = 0   #cria a coluna de desconto, colocando o valor 0 em todas as linnhas \n",
    "\n",
    "#troca do nome das colunas\n",
    "tabela_xml.rename(columns = {'user_id':'id', 'name':'nome', 'email_user':'email', 'phone':'telefone', \n",
    "                            'buy_value':'valor'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concatenação dos 3 arquivos \n",
    "tabela_usuarios_final = pd.concat([df['usuarios'], tabela_csv, tabela_xml],  sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrige_telefone(telefone):   #O telefone deve ser +55DDDNUMERO. Ex: (+5516981773421)  \n",
    "    \n",
    "    if telefone is None or telefone == \"\":   #Se não conter telefone\n",
    "        return None   #retorna um valor nulo\n",
    "    telefone = re.sub('[^0-9]',\"\", telefone)   #filtra os elementos que o telefone pode ter, números de 0 a 9 \n",
    "\n",
    "    try:\n",
    "        telefone.index('55', 0, 2)   #procura por 55 nas primeiras posições\n",
    "        #se o 55 é realmente o código do país, e não o DDD \n",
    "        return ('+'+telefone)  if len(telefone) == 12 else ('+55'+telefone)\n",
    "    except:\n",
    "        return ('+55'+telefone)   #se não conter 55 nas primeiras posições concatena um +55 no início\n",
    "    \n",
    "#executa a função em todos os telefones\n",
    "tabela_usuarios_final['telefone'] = list(map(corrige_telefone, tabela_usuarios_final['telefone'].tolist()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrige_valor(valor):   #O Valor deve ser formatado como dinheiro (real). Ex: 999,00 \n",
    "    \n",
    "    if valor is None or valor == \"\":   #Se não conter valor\n",
    "        return None   #retorna um valor nulo\n",
    "    \n",
    "    #troca as virgulas por pontos,para poder manipular como float \n",
    "    valor = float(re.sub('[^0-9.,]',\"\", str(valor)).replace(',', '.')) \n",
    "    #delimita em duas casas decimais, completando com zero, e troca os pontos por vírgulas\n",
    "    return f'{valor:.2f}'.replace('.', ',') \n",
    "\n",
    "#executa a função em todos os valores\n",
    "tabela_usuarios_final['valor'] = list(map(corrige_valor, tabela_usuarios_final['valor'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrige_desconto(desconto):   #corrige a coluna 'desconto' \n",
    "\n",
    "    if desconto is None or desconto == \"-\":   #Se não conter desconto, ou conter \"-\"\n",
    "        return 0   # retorna 0\n",
    "\n",
    "    return desconto #Caso contrário, retorna o valor do desconto \n",
    "  \n",
    "#executa a função em todos os descontos \n",
    "tabela_usuarios_final['desconto'] = list(map(corrige_desconto, tabela_usuarios_final['desconto'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_valor_com_desconto(valor, desconto):  #O valor_com_desconto deve ser calculado com o valor_total - desconto%\n",
    "\n",
    "    valor = float(valor.replace(',', '.'))     \n",
    "    valor_com_desconto = valor - (valor*float(desconto)/100) #calcula valor com desconto\n",
    "    #define o padrão com duas casas decimais, arredonda os decimais, e completa com 0 quando necessário\n",
    "    return (\"%.2f\" % round(valor_com_desconto,2)).replace('.', ',') \n",
    "\n",
    "#executa a função em todos os valores e descontos        \n",
    "tabela_usuarios_final['valor_com_desconto'] = list(map(gera_valor_com_desconto, tabela_usuarios_final['valor'].tolist(), \n",
    "                                                tabela_usuarios_final['desconto'].tolist()))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_data_hora_timestamp(data_hora):   #Datas no formato TIMESTAMP\n",
    "\n",
    "    if data_hora is None or data_hora == \"\":   #Se não conter data e hora\n",
    "        return None   \n",
    "    \n",
    "    data_hora = datetime.strptime(data_hora,'%d/%m/%Y %H:%M:%S')  #converte os valores da tabela para datatime\n",
    "    return str(datetime.timestamp(data_hora))   #converte para timestamp\n",
    "    \n",
    "#executa a função em todas as data/horas\n",
    "df['dependentes'].data_hora = list(map(converte_data_hora_timestamp, df['dependentes'].data_hora.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gera_csv(tabela_usuarios_final, dependentes):   #Gera dois arquivos csv com as páginas atualizadas\n",
    "\n",
    "    \n",
    "    #Alterações na tabelas    \n",
    "    #Escolhe as colunas \n",
    "    tabela_usuarios_final = tabela_usuarios_final[[\"id\", \"nome\", \"email\", \"telefone\", \"valor\", \"valor_com_desconto\"]]  \n",
    "    #Renomeia nomes das colunas\n",
    "    tabela_usuarios_final = tabela_usuarios_final.rename(columns = {'valor':'valor_total'})\n",
    "    #ordenação do dataframe pela coluna 'id'\n",
    "    tabela_usuarios_final['id'] = pd.to_numeric(tabela_usuarios_final['id'])\n",
    "    tabela_usuarios_final = tabela_usuarios_final.sort_values(by='id')\n",
    "\n",
    "    #Renomeia nomes das colunas\n",
    "    dependentes = dependentes.rename(columns = {'user_id':'usuario_id'})\n",
    "   \n",
    "    #Nomeação dos arquivos\n",
    "    now = datetime.now()    #data/hora atual \n",
    "    hora_usuarios =  now.strftime(\"usuarios.data%b-%d-%G.csv\")\n",
    "    hora_dependentes =  now.strftime(\"dependentes.data%b-%d-%G.csv\")\n",
    "    \n",
    "    #geração dos arquivos\n",
    "    tabela_usuarios_final.to_csv(hora_usuarios, sep=';', index=False)\n",
    "    dependentes.to_csv(hora_dependentes, sep=';', index=False)\n",
    "    \n",
    "    return {'Usuarios': tabela_usuarios_final, 'Dependentes': dependentes}   #retorna como dict\n",
    "    \n",
    "#Executa a função com as páginas como parâmetro\n",
    "df_final = gera_csv(tabela_usuarios_final, df['dependentes'])      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_banco_de_dados(db):  #Cria um banco de dados sqlite e as respectivas tabelas\n",
    "    \n",
    "    \n",
    "    if(os.path.isfile(db)):   #verifica se o banco já existia\n",
    "        os.remove(db)   #exclui banco anterior para colocar os dados novos\n",
    "    conn = sqlite3.connect(db)   #conecta no arquivo\n",
    "    c = conn.cursor()   #cursor pra poder fazer as operações\n",
    "    \n",
    "    # Criação das tabelas\n",
    "    c.execute('''CREATE TABLE Usuarios(\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    nome TEXT NOT NULL,\n",
    "                    email TEXT,\n",
    "                    telefone TEXT,\n",
    "                    valor_total TEXT,\n",
    "                    valor_com_desconto TEXT)''')\n",
    "    c.execute('''CREATE TABLE Dependentes(\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    usuario_id INTEGER NOT NULL,\n",
    "                    dependente_id INTEGER NOT NULL,\n",
    "                    data_hora INTEGER,\n",
    "                    FOREIGN KEY(usuario_id) REFERENCES Usuarios(id),\n",
    "                    FOREIGN KEY(dependente_id) REFERENCES Usuarios(id))''')\n",
    "    \n",
    "    conn.commit() #salva alterações, guarda o que foi feito\n",
    "    conn.close() #fecha conexão\n",
    "\n",
    "\n",
    "db = \"importacao.db\"\n",
    "cria_banco_de_dados(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def insere_no_banco(db, data):   #Insere as informações dos dataframes no banco\n",
    "    \n",
    "    \n",
    "    engine = create_engine(f'sqlite:///{db}', echo=False)   #conexão com o banco\n",
    "    for table in list(data.keys()):   #insere os dados nas tabelas\n",
    "        data[table].to_sql(table, con=engine, if_exists='append', index=False)\n",
    "\n",
    "insere_no_banco(db, df_final)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID do usuário             Usuário  ID do dependente       Dependentes\n",
      "0            8056          Nia Nickle              8001     Nannette Buse\n",
      "1            8094     Charisse Baltes              8017   Bessie Pressman\n",
      "2            8087       Shaunna Myers              8064       Herb Sheats\n",
      "3            8019         Del Mayorga              8008   Christoper Kier\n",
      "4            8027      Kandis Marchan              8081      Jeneva Nesby\n",
      "5            8006       Myesha Vester              8012  Raymundo Sawicki\n",
      "6            8041    Marietta Longley              8084      Eryn Coatney\n",
      "7            8067        Vernell Tarr              8039     Madie Brodeur\n",
      "8            8057     Syreeta Gilland              8080       Dell Burrus\n",
      "9            8068  Angelena Nettleton              8036     Jesica Sanger\n",
      "10           8010        Tashia Rasor              8026     Xochitl Spain\n",
      "11           8044        Cammie Nason              8045      Hoyt Greenan\n",
      "12           8086        Jerica Eason              8073       Shella Wold\n",
      "13           8040        Lea Palencia              8021      Sang Drexler\n",
      "14           8037      Marnie Gilmore              8065   Katerine Ledger\n",
      "15           8053       Ciera Weglarz              8070   Patti Catalfamo\n",
      "16           8019         Del Mayorga              8033      Lacie Dewall\n"
     ]
    }
   ],
   "source": [
    "def consulta_no_banco(db, query):   #Realiza consultas no banco\n",
    "    \n",
    "    if(os.path.isfile(db)):\n",
    "        conn = sqlite3.connect(db)   #conexão com o banco\n",
    "        df = pd.read_sql_query(query,conn)   #executa o comando da query\n",
    "        conn.close()   #fecha conexão\n",
    "        return df\n",
    "    return None\n",
    "        \n",
    "print(consulta_no_banco(db, \"SELECT u1.id AS 'ID do usuário', u1.nome AS 'Usuário', u2.id AS 'ID do dependente', u2.nome AS 'Dependentes' \"+ \\\n",
    "                   \"FROM Usuarios AS u1, Usuarios AS u2, Dependentes AS d WHERE u1.id=d.usuario_id AND u2.id=d.dependente_id\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
